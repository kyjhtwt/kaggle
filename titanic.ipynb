{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_survive_rate(data, column=-1, cond=-1):\n",
    "    copied_data = data.copy()\n",
    "    if(column != -1):\n",
    "        if(cond != -1):\n",
    "            copied_data = copied_data[copied_data[column] == cond]\n",
    "        else:\n",
    "            pass\n",
    "    elif(cond != -1):\n",
    "        copied_data = copied_data[cond]\n",
    "    else:\n",
    "        pass\n",
    "    return (copied_data[copied_data['Survived'] == 1].shape[0] / copied_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_range(x, range_len):\n",
    "    return round(x / 5) * 5 + 2.5\n",
    "def is_infant(x):\n",
    "    if(x <= 11): return 1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3838383838383838"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Survived.sum() / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.copy()\n",
    "testset = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns=['Cabin', 'Ticket', 'Name'])\n",
    "testset = testset.drop(columns=['Cabin', 'Ticket', 'Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = dataset.copy()\n",
    "temp_df = temp_df.fillna(-1)\n",
    "condition = temp_df['Age'] >= 0\n",
    "temp_df = temp_df[condition]\n",
    "age_sum = temp_df['Age'].sum(axis=0)\n",
    "valid_age_cnt = temp_df['Age'].count()\n",
    "age_avg = round(age_sum / valid_age_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Age'] = dataset['Age'].fillna(age_avg)\n",
    "testset['Age'] = testset['Age'].fillna(age_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embarked_mark = dataset['Embarked']\n",
    "embarked_c = dataset[Embarked_mark == 'C']\n",
    "embarked_s = dataset[Embarked_mark == 'S']\n",
    "embarked_q = dataset[Embarked_mark == 'Q']\n",
    "survived = dataset['Survived'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5535714285714286 0.38961038961038963 0.33695652173913043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/test/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/envs/test/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "/opt/anaconda3/envs/test/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "survival_rate_c = embarked_c[survived].shape[0] / embarked_c.shape[0]\n",
    "survival_rate_s = embarked_s[survived].shape[0] / embarked_s.shape[0]\n",
    "survival_rate_q = embarked_q[survived].shape[0] / embarked_q.shape[0]\n",
    "print(survival_rate_c, survival_rate_q, survival_rate_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns='Embarked')\n",
    "testset = testset.drop(columns='Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2517482517482518\n",
      "0.6857142857142857\n"
     ]
    }
   ],
   "source": [
    "sibsp_dataset = dataset[dataset['SibSp'] > 0]\n",
    "sibsp_dataset_male = sibsp_dataset[sibsp_dataset['Sex'] == 'male']\n",
    "sibsp_dataset_female = sibsp_dataset[sibsp_dataset['Sex'] == 'female']\n",
    "print(sibsp_dataset_male[sibsp_dataset_male['Survived'] == 1].shape[0] / sibsp_dataset_male.shape[0])\n",
    "print(sibsp_dataset_female[sibsp_dataset_female['Survived'] == 1].shape[0] / sibsp_dataset_female.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18890814558058924 0.7420382165605095\n"
     ]
    }
   ],
   "source": [
    "male_data = dataset[dataset['Sex'] == 'male']\n",
    "female_data = dataset[dataset['Sex'] == 'female']\n",
    "male_data_survived_rate = male_data[male_data['Survived'] == 1].shape[0] / male_data.shape[0]\n",
    "female_data_survived_rate = female_data[female_data['Survived'] == 1].shape[0] / female_data.shape[0]\n",
    "print(male_data_survived_rate, female_data_survived_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_plot_dataset = dataset.copy()\n",
    "age_plot_dataset['Age'] = age_plot_dataset['Age'].apply(lambda x: get_age_range(x, 5))\n",
    "ages = age_plot_dataset['Age'].unique()\n",
    "survived_rate_range_ages = []\n",
    "for age in ages:\n",
    "    survived_rate = get_survive_rate(age_plot_dataset, 'Age', age)\n",
    "    survived_rate_range_ages.append(survived_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 17 artists>"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(ages, survived_rate_range_ages, width=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Infant'] = dataset['Age'].apply(lambda x : is_infant(x))\n",
    "testset['Infant'] = testset['Age'].apply(lambda x : is_infant(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5056497175141242"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = dataset.copy()\n",
    "have_Parch = temp['Parch'] >= 1\n",
    "have_SibSp = temp['SibSp'] >= 1\n",
    "get_survive_rate(temp[(have_Parch | have_SibSp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['family'] = (dataset['Parch'] + dataset['SibSp'])\n",
    "dataset = dataset.drop(columns='PassengerId')\n",
    "testset['family'] = (testset['Parch'] + testset['SibSp'])\n",
    "testset = testset.drop(columns='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_excel('preprocessing.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['Pclass', 'Sex']\n",
    "for col in categorical_columns:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(dataset[col].values)\n",
    "    dataset[col] = le.transform(dataset[col].values)\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(testset[col].values)\n",
    "    testset[col] = le.transform(testset[col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.pop('Survived')\n",
    "y_test = test.pop('Survived')\n",
    "y_val = val.pop('Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = df_to_dataset(test)\n",
    "# train_data = df_to_dataset(train)\n",
    "# val_data = df_to_dataset(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(optimizer):\n",
    "    ann = Sequential()\n",
    "    ann.add(Dense(units=32, kernel_initializer='glorot_uniform', activation='relu'))\n",
    "    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n",
    "    ann.add(Dropout(rate=0.5))\n",
    "    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n",
    "    ann.add(Dropout(rate=0.5))\n",
    "    ann.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='sigmoid'))\n",
    "    ann.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/test/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 6ms/step - loss: 1.8297 - accuracy: 0.5712 - val_loss: 0.6075 - val_accuracy: 0.6993\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 1.0313 - accuracy: 0.6116 - val_loss: 0.5976 - val_accuracy: 0.6923\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9576 - accuracy: 0.6134 - val_loss: 0.5657 - val_accuracy: 0.6993\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.9207 - accuracy: 0.6257 - val_loss: 0.5463 - val_accuracy: 0.7203\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8635 - accuracy: 0.6555 - val_loss: 0.5527 - val_accuracy: 0.7203\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7354 - accuracy: 0.6626 - val_loss: 0.5505 - val_accuracy: 0.7273\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.6696 - val_loss: 0.5556 - val_accuracy: 0.7273\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7596 - accuracy: 0.6485 - val_loss: 0.5681 - val_accuracy: 0.7273\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.6819 - val_loss: 0.5655 - val_accuracy: 0.7273\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6696 - val_loss: 0.5634 - val_accuracy: 0.7273\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.6450 - val_loss: 0.5586 - val_accuracy: 0.7203\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.7047 - val_loss: 0.5579 - val_accuracy: 0.7273\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.6731 - val_loss: 0.5533 - val_accuracy: 0.7343\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.6801 - val_loss: 0.5531 - val_accuracy: 0.7273\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.6960 - val_loss: 0.5373 - val_accuracy: 0.7273\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.6784 - val_loss: 0.5405 - val_accuracy: 0.7273\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6113 - accuracy: 0.6837 - val_loss: 0.5355 - val_accuracy: 0.7273\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.6749 - val_loss: 0.5314 - val_accuracy: 0.7203\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.7065 - val_loss: 0.5336 - val_accuracy: 0.7203\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.6995 - val_loss: 0.5235 - val_accuracy: 0.7203\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.6889 - val_loss: 0.5384 - val_accuracy: 0.7133\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5916 - accuracy: 0.7030 - val_loss: 0.5171 - val_accuracy: 0.7413\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.7012 - val_loss: 0.5117 - val_accuracy: 0.7273\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.6977 - val_loss: 0.5304 - val_accuracy: 0.7343\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7188 - val_loss: 0.5034 - val_accuracy: 0.7273\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7206 - val_loss: 0.4948 - val_accuracy: 0.7203\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7346 - val_loss: 0.4930 - val_accuracy: 0.7343\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7100 - val_loss: 0.4976 - val_accuracy: 0.7203\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7329 - val_loss: 0.5017 - val_accuracy: 0.7133\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.7170 - val_loss: 0.5010 - val_accuracy: 0.7343\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7434 - val_loss: 0.4973 - val_accuracy: 0.7692\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7540 - val_loss: 0.4945 - val_accuracy: 0.7622\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7329 - val_loss: 0.4826 - val_accuracy: 0.7622\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7575 - val_loss: 0.4941 - val_accuracy: 0.7692\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7698 - val_loss: 0.4919 - val_accuracy: 0.7483\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7663 - val_loss: 0.4791 - val_accuracy: 0.7692\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7592 - val_loss: 0.4837 - val_accuracy: 0.7413\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7592 - val_loss: 0.5070 - val_accuracy: 0.7343\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7768 - val_loss: 0.4646 - val_accuracy: 0.7762\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.7522 - val_loss: 0.4664 - val_accuracy: 0.7483\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7293 - val_loss: 0.4637 - val_accuracy: 0.7622\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7575 - val_loss: 0.5125 - val_accuracy: 0.7552\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7821 - val_loss: 0.4793 - val_accuracy: 0.7832\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.5307 - accuracy: 0.7698 - val_loss: 0.4751 - val_accuracy: 0.7762\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7715 - val_loss: 0.4643 - val_accuracy: 0.7902\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7592 - val_loss: 0.4529 - val_accuracy: 0.7832\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.7575 - val_loss: 0.4801 - val_accuracy: 0.7692\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7715 - val_loss: 0.4617 - val_accuracy: 0.7902\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7786 - val_loss: 0.4464 - val_accuracy: 0.7762\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7803 - val_loss: 0.4598 - val_accuracy: 0.7692\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7750 - val_loss: 0.4668 - val_accuracy: 0.7832\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7768 - val_loss: 0.4541 - val_accuracy: 0.7902\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7944 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7803 - val_loss: 0.4794 - val_accuracy: 0.7692\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7645 - val_loss: 0.4480 - val_accuracy: 0.7832\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7750 - val_loss: 0.4768 - val_accuracy: 0.7762\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7838 - val_loss: 0.4777 - val_accuracy: 0.7832\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8049 - val_loss: 0.4838 - val_accuracy: 0.7762\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7838 - val_loss: 0.4625 - val_accuracy: 0.7762\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7873 - val_loss: 0.4528 - val_accuracy: 0.7762\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7680 - val_loss: 0.4889 - val_accuracy: 0.7483\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7750 - val_loss: 0.4820 - val_accuracy: 0.7762\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7803 - val_loss: 0.4853 - val_accuracy: 0.7622\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7873 - val_loss: 0.4674 - val_accuracy: 0.7692\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7856 - val_loss: 0.4640 - val_accuracy: 0.7622\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7909 - val_loss: 0.4523 - val_accuracy: 0.7832\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7786 - val_loss: 0.4636 - val_accuracy: 0.7622\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7944 - val_loss: 0.4396 - val_accuracy: 0.7972\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7926 - val_loss: 0.4512 - val_accuracy: 0.7832\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.8014 - val_loss: 0.4304 - val_accuracy: 0.7762\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7838 - val_loss: 0.4347 - val_accuracy: 0.8042\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.8049 - val_loss: 0.4703 - val_accuracy: 0.7832\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7803 - val_loss: 0.4395 - val_accuracy: 0.7972\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7979 - val_loss: 0.4365 - val_accuracy: 0.7832\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7909 - val_loss: 0.4307 - val_accuracy: 0.7902\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7909 - val_loss: 0.4306 - val_accuracy: 0.8042\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7979 - val_loss: 0.4513 - val_accuracy: 0.7762\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7944 - val_loss: 0.4479 - val_accuracy: 0.7762\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7821 - val_loss: 0.4325 - val_accuracy: 0.8112\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7821 - val_loss: 0.4357 - val_accuracy: 0.7832\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7961 - val_loss: 0.4486 - val_accuracy: 0.7762\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7961 - val_loss: 0.5000 - val_accuracy: 0.7692\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7821 - val_loss: 0.5476 - val_accuracy: 0.7483\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7909 - val_loss: 0.4724 - val_accuracy: 0.7622\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8190 - val_loss: 0.4718 - val_accuracy: 0.7762\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7926 - val_loss: 0.4622 - val_accuracy: 0.7832\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7979 - val_loss: 0.4355 - val_accuracy: 0.7902\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7909 - val_loss: 0.4392 - val_accuracy: 0.8042\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7996 - val_loss: 0.4310 - val_accuracy: 0.7832\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.8049 - val_loss: 0.4244 - val_accuracy: 0.8042\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7891 - val_loss: 0.4277 - val_accuracy: 0.7972\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8137 - val_loss: 0.4256 - val_accuracy: 0.7692\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7803 - val_loss: 0.4824 - val_accuracy: 0.7762\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8102 - val_loss: 0.4181 - val_accuracy: 0.8112\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7873 - val_loss: 0.4339 - val_accuracy: 0.8042\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8225 - val_loss: 0.4307 - val_accuracy: 0.7972\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7891 - val_loss: 0.4506 - val_accuracy: 0.8252\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7944 - val_loss: 0.4442 - val_accuracy: 0.8112\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8049 - val_loss: 0.4349 - val_accuracy: 0.8042\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8014 - val_loss: 0.4197 - val_accuracy: 0.7622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9924767310>"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = tf.optimizers.Adam(lr=0.001)\n",
    "ann = ANN(opt)\n",
    "ann.fit(train, y_train,batch_size=BATCH_SIZE, epochs=100, validation_data=(val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7821\n"
     ]
    }
   ],
   "source": [
    "score = ann.evaluate(test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 926us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(testset)\n",
    "y_pred = (y_pred > 0.5) * 1\n",
    "submission = pd.DataFrame({\"PassengerId\": test_df['PassengerId'], \"Survived\":np.reshape(y_pred, len(y_pred))})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8aac0b6a3e67f35bcd67088a857342b2a6b50e1135570ee0f841fb10732c056"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
